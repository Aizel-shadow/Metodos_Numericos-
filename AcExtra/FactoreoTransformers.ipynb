{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cde3a4e2",
   "metadata": {},
   "source": [
    "FACTOREO EN TRANSFORMERS \n",
    "\n",
    "Nombre: Alegria Farinango\n",
    "\n",
    "Fecha: 27/01/2026\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbbe6cfd",
   "metadata": {},
   "source": [
    "Investigue sobre el uso de factoreo de matrices en la arquitectura de redes neuronales Transformers. \n",
    "\n",
    "\n",
    "En la arquitectura original de un Transformer, las capas más pesadas son las capas lineales (Feed-Forward) y las matrices de Proyección de Atención (Query, Key, Value). Estas matrices suelen ser enormes, con dimensiones de miles por miles de parámetros.El factoreo de matrices consiste en descomponer una matriz grande y densa $W$ de tamaño $m \\times n$ en el producto de dos matrices más pequeñas $A$ ($m \\times r$) y $B$ ($r \\times n$), donde el rango $r$ es mucho menor que $m$ o $n$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "001b97b6",
   "metadata": {},
   "source": [
    "Indique las razones y las ventajas de realizar esta operación. \n",
    "\n",
    "A. Reducción drástica de parámetros \n",
    "\n",
    "Si se tiene una matriz de $1000 \\times 1000$, tiene 1,000,000 de parámetros. Si la factoriza con un rango $r=10$, pasa a tener dos matrices ($1000 \\times 10$ y $10 \\times 1000$), sumando solo 20,000 parámetros. ¡Es una reducción del 98%!\n",
    "\n",
    "B. Menor consumo de Memoria VRAM\n",
    "\n",
    "Esta es la ventaja más crítica. Al reducir el número de parámetros que se deben cargar en la tarjeta de video (GPU), es posible:\n",
    "\n",
    "    Entrenar modelos gigantes en hardware doméstico.\n",
    "\n",
    "    Ejecutar modelos (inferencia) en dispositivos móviles o con pocos recursos.\n",
    "\n",
    "C. Velocidad de Entrenamiento y Transferencia\n",
    "\n",
    "En técnicas como LoRA, al entrenar solo las \"matrices pequeñas\", los archivos resultantes (checkpoints) pesan megabytes en lugar de gigabytes. Esto permite compartir y cambiar entre diferentes tareas (por ejemplo, pasar de un modelo que escribe código a uno que escribe poesía) en milisegundos.\n",
    "\n",
    "D. Regularización y prevención de Overfitting\n",
    "\n",
    "Al forzar a la red a trabajar con una aproximación de bajo rango, se eliminan \"ruidos\" o detalles innecesarios de los datos, obligando al modelo a aprender las características más generales y robustas, lo que a veces mejora su capacidad de generalización."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
